{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math Problem Solving\n",
    "\n",
    "In this example, we build a simple workflow for solving [MATH problems](https://github.com/hendrycks/math). \n",
    "\n",
    "**Example Problen and Solution:**\n",
    "\n",
    "P: The Smith family has 4 sons and 3 daughters. In how many ways can they be seated in a row of 7 chairs such that at least 2 boys are next to each other?\n",
    "\n",
    "S: This problem is a perfect candidate for complementary counting.  It will be fairly difficult to try to count this directly, since there are lots of possible cases (just two are BBBBGGG and BGGBBGB, where B is a boy and G is a girl).  But there is only one way to assign genders to the seating so that no two boys are next to each other, and that is BGBGBGB. If we seat the children as BGBGBGB, then there are 4 factorial orderings for the 4 boys, and 3 factorial orderings for the 3 girls, giving a total of `4! x 3! = 144` seatings for the 7 children. These are the seatings that we don't want, so to count the seatings that we do want, we need to subtract these seatings from the total number of seatings without any restrictions.  Since there are 7 kids, there are 7 factorial ways to seat them. So the answer is \n",
    "\n",
    "```\n",
    "7! - (4! x 3!) = 5040-144 = 4896\n",
    "```\n",
    "\n",
    "\n",
    "The workflow involves 2 agents:\n",
    "- **Modeling (or interpreter) agent**: analyzes the problem and models the problem with equations.\n",
    "- **Solver agent**: focuses on solving the generated model to get the answer.\n",
    "\n",
    "![math](../imgs/math.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Setup\n",
    "\n",
    "First, let's set the environment for workflow execution. We use openai model in this example, please set your key in `.env` file as:\n",
    "\n",
    "OPENAI_API_KEY=\"your-openai-key\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Check Math Workflow\n",
    "\n",
    "The implementation is based on `langchain` and is avaibale in `workflow.py`. \n",
    "\n",
    "Try it out with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': \"To solve the problem, we need to analyze the pattern of the student's actions as he opens the lockers.\\n\\n1. **Initial Setup**: There are 1024 lockers, all initially closed.\\n\\n2. **First Pass**: The student opens locker 1, then skips locker 2, opens locker 3, skips locker 4, and so on. This means he opens all odd-numbered lockers on the first pass:\\n   - Opened lockers: 1, 3, 5, ..., 1023 (total of 512 lockers).\\n\\n3. **Turning Around**: When he reaches locker 1024, he turns around and starts back. The first closed locker he encounters is locker 2 (since all odd-numbered lockers are open). He opens locker 2, then skips locker 4, opens locker 6, skips locker 8, and continues this pattern:\\n   - Opened lockers: 2, 6, 10, ..., 1022 (total of 256 lockers).\\n\\n4. **Subsequent Passes**: The student continues this process, alternating between opening the first closed locker he encounters and then skipping the next one. Each time he turns around, he opens lockers in a specific pattern:\\n   - On the third pass, he will open lockers 4, 12, 20, ..., and so on.\\n   - On the fourth pass, he will open lockers 8, 24, 40, ..., and so on.\\n\\n5. **General Pattern**: Each pass can be described as opening lockers that are multiples of \\\\(2^n\\\\) where \\\\(n\\\\) is the pass number (starting from 0). The number of lockers opened in each pass decreases as follows:\\n   - 1st pass: \\\\(2^0 = 1\\\\) (opened 512 lockers)\\n   - 2nd pass: \\\\(2^1 = 2\\\\) (opened 256 lockers)\\n   - 3rd pass: \\\\(2^2 = 4\\\\) (opened 128 lockers)\\n   - 4th pass: \\\\(2^3 = 8\\\\) (opened 64 lockers)\\n   - 5th pass: \\\\(2^4 = 16\\\\) (opened 32 lockers)\\n   - 6th pass: \\\\(2^5 = 32\\\\) (opened 16 lockers)\\n   - 7th pass: \\\\(2^6 = 64\\\\) (opened 8 lockers)\\n   - 8th pass: \\\\(2^7 = 128\\\\) (opened 4 lockers)\\n   - 9th pass: \\\\(2^8 = 256\\\\) (opened 2 lockers)\\n   - 10th pass: \\\\(2^9 = 512\\\\) (opened 1 locker)\\n\\n6. **Final Pass**: The last locker opened will be the last locker he encounters on the final pass. Since he opens lockers in the order of their numbers, the last locker opened will be locker 1024.\\n\\nThus, the number of the last locker he opens is:\\n\\n\\\\[\\n\\\\boxed{1024}\\n\\\\]\"}\n"
     ]
    }
   ],
   "source": [
    "%run workflow.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Optimize The Workflow\n",
    "\n",
    "The workflow entry point is already registered using annotation `cognify.register_workflow`.\n",
    "\n",
    "Here we configure the optimization pipeline:\n",
    "1. Define the evaluation method\n",
    "2. Define the data loader\n",
    "3. Config the optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Use LLM-as-judge\n",
    "\n",
    "As you can see the standard solution includes both the result and the detailed steps required to achieve it. We utilize an LLM agent to evaluate the generated output for completeness and correctness.\n",
    "\n",
    "The agent assigns a score on a scale of 0 to 10, accounting for partially correct answers.\n",
    "\n",
    "We implement the scoring agent with `langchain` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cognify\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Initialize the model\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Force agent to respond with a score\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "class Assessment(BaseModel):\n",
    "    score: int\n",
    "    \n",
    "parser = PydanticOutputParser(pydantic_object=Assessment)\n",
    "\n",
    "@cognify.register_evaluator\n",
    "def llm_judge(workflow_input, workflow_output, ground_truth):\n",
    "    evaluator_prompt = \"\"\"\n",
    "You are a math problem evaluator. Your task is to grade the the answer to a math proble by assessing its correctness and completeness.\n",
    "\n",
    "You should not solve the problem by yourself, a standard solution will be provided. \n",
    "\n",
    "Please rate the answer with a score between 0 and 10.\n",
    "    \"\"\"\n",
    "    evaluator_template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", evaluator_prompt),\n",
    "            (\"human\", \"problem:\\n{problem}\\n\\nstandard solution:\\n{solution}\\n\\nanswer:\\n{answer}\\n\\nYou response format:\\n{format_instructions}\\n\"),\n",
    "        ]\n",
    "    )\n",
    "    evaluator_agent = evaluator_template | model | parser\n",
    "    assess = evaluator_agent.invoke(\n",
    "        {\n",
    "            \"problem\": workflow_input, \n",
    "            \"answer\": workflow_output, \n",
    "            \"solution\": ground_truth, \n",
    "            \"format_instructions\": parser.get_format_instructions()\n",
    "        }\n",
    "    )\n",
    "    return assess.score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Load the Data\n",
    "\n",
    "We provide the subsampled math data in `data._json` file for you to start with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data should be formatted to align with the function signature of both the workflow entry point and the evaluator.\n",
    "\n",
    "Signatures are:\n",
    "- workflow (workflow_input) -> {'workflow_output': ...}\n",
    "- evaluator (workflow_input, workflow_output, ground_truth) -> int\n",
    "\n",
    "The workflow input expects the `workflow_input` field and will forward `workflow_output` to the evaluator. \n",
    "\n",
    "Additionally, the data loader needs to provide `ground_truth` to match the evaluator signature. **Note**: All of these variable names are *customizable* as long as they are consistent with each other.\n",
    "\n",
    "With above rule, each data item should be formatted a tuple of (input, ground truth), each being a dictionary with required fields:\n",
    "\n",
    "```python\n",
    "(\n",
    "    {'workflow_input': ...},\n",
    "    {'ground_truth': ...}\n",
    ")\n",
    "```\n",
    "\n",
    "The complete data loader code is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "@cognify.register_data_loader\n",
    "def load_data():\n",
    "    with open(\"data._json\", \"r\") as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "    random.seed(42)\n",
    "    random.shuffle(data) \n",
    "    # format to (input, output) pairs\n",
    "    new_data = []\n",
    "    for d in data:\n",
    "        input_sample = {\n",
    "            'workflow_input': d[\"problem\"],\n",
    "        }\n",
    "        ground_truth = {\n",
    "            'ground_truth': d[\"solution\"],\n",
    "        }\n",
    "        new_data.append((input_sample, ground_truth))\n",
    "    # train, val, test split\n",
    "    return new_data[:30], None, new_data[30:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Config the optimizer\n",
    "\n",
    "Let's use the default configuration to optimize this workflow. This will decide whether or not to add fewshot examples from the training data and whether to apply chain-of-thought prompting to each agent.\n",
    "\n",
    "Additionally, the original workflow use `gpt-4o` for both agents, we also want to tune the model selection to save cost.\n",
    "\n",
    "The final search space:\n",
    "- 2 fewshot examples to add for each agent\n",
    "- whether to apply Chain-of-thought to each agent\n",
    "- select `gpt-4o` or `gpt-4o-mini` for each agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cognify.hub.search import default\n",
    "\n",
    "model_configs = [\n",
    "    # OpenAI models\n",
    "    cognify.LMConfig(model='gpt-4o-mini', kwargs={'temperature': 0, 'max_tokens': 300}),\n",
    "    cognify.LMConfig(model='gpt-4o', kwargs={'temperature': 0, 'max_tokens': 300}),\n",
    "]\n",
    "\n",
    "search_settings = default.create_search(\n",
    "    model_selection_cog=model_configs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Start the Optimization\n",
    "\n",
    "You can save the above configs in `config.py` file and use Cognify's CLI to fire the optimization with:\n",
    "\n",
    "```console\n",
    "$ cognify optimize workflow.py\n",
    "```\n",
    "\n",
    "Alternatively you can run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, dev = load_data()\n",
    "\n",
    "opt_cost, pareto_frontier, opt_logs = cognify.optimize(\n",
    "    script_path=\"workflow.py\",\n",
    "    control_param=search_settings,\n",
    "    train_set=train,\n",
    "    val_set=val,\n",
    "    eval_fn=llm_judge,\n",
    "    force=True, # This will overwrite the existing results\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Optimization Results\n",
    "\n",
    "Cognfiy will output each optimized workflow to a `.cog` file. For this workflow, the optimizer applies the following optimizations:\n",
    "- use few-shot examples with GPT-4o-mini for the problem modeling (or interpreter) agent\n",
    "- use few-shot examples for the model solver agent\n",
    "\n",
    "The final optimized workflow is depicted below, with optimizations highlighted in green.\n",
    "\n",
    "![finrobot-opt](../imgs/math_optimized.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the modeling agent, the following few-shot examples are selected (outputs truncated for brevity):\n",
    "\n",
    "> **Demonstration 1:**  \n",
    "> \tInput (problem): \"A paperboy delivers newspapers to 10 houses along Main Street. Wishing to save effort, he doesn't always deliver to every house, but to avoid being fired he never misses three consecutive houses..\"  \n",
    ">   \n",
    "> \tReasoning: \"To solve this problem, we can use a combinatorial approach with dynamic programming. Let's define a sequence where each term represents the number of ways the paperboy can deliver newspapers...\"  \n",
    ">   \n",
    "> \tOutput (response): \"To solve the problem, we define `a_n` as the number of ways the paperboy can deliver newspapers to `n` houses such that he never misses three consecutive houses. The base cases are ...\"  \n",
    "\n",
    "> **Demonstration 2:**  \n",
    "> \tInput (problem): \"A drawer in a darkened room contains $100$ red socks, $80$ green socks, $60$ blue socks and $40$ black socks. A youngster selects socks one at a time from the drawer but is unable to see the color...\"  \n",
    ">   \n",
    "> \tReasoning: \"To solve this problem, we need to determine the minimum number of socks that must be selected to ensure that there are at least 10 pairs of socks. A pair is defined as two socks of the same color...\"  \n",
    ">   \n",
    "> \tOutput (response): \"To ensure at least 10 pairs of socks, we consider the worst-case scenario where we form 9 pairs and have additional single socks of other colors. We can have 9 pairs of one color (18 socks)...\"  \n",
    "\n",
    "This example shows how even without explicitly adding reasoning prompts, few-shot examples can learn from the entire optimization process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out more details on [how to interpret optimization results](https://cognify-ai.readthedocs.io/en/latest/user_guide/tutorials/interpret.html#detailed-transformation-trace)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fresh_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
